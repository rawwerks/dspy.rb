# Composable System Prompt Context

**Date:** 2026-02-06
**Status:** Brainstorm

## What We're Building

A mechanism for DSPy::Module subclasses (especially agent loops) to declare **composable context modules** that get assembled into the system prompt of all inner Predict calls.

Today, the system prompt is a monolithic string auto-generated by `Prompt#render_system_prompt` from schema + format instructions + examples + instruction. There's no way for a Module to inject additional context (persona, rules, domain knowledge) without hacking the instruction string or manually injecting markdown.

## Why This Approach

### The Problem

When building a custom `DSPy::Module` like an AgentLoop:

1. The agent needs shared context (persona, guardrails, domain rules) across multiple inner Predict calls
2. The only injection point today is `Signature.description`, which is meant for the task objective, not ambient context
3. Users resort to manually injecting markdown files (e.g., `agent_instructions.md`) into prompts
4. ReAct and CodeAct's inner signatures have hardcoded descriptions with no way to propagate user-provided context

### The Analogy: Skills

The design is inspired by Claude Code's Skills model:
- Each "skill" is a self-contained context module (persona, rules, domain knowledge)
- Multiple skills compose together at runtime
- The system prompt is assembled from the active skill set
- Individual pieces stay freeform (markdown), but the **composition is structured**

### Why Module-Level (Approach B)

- Agents have multiple inner Predict calls (e.g., ReAct has `thought_generator` + `observation_processor`)
- Context should be declared once on the Module and propagate to all inner predictions
- Avoids manual wiring of context to each Prompt individually
- Follows existing DSPy pattern of Module settings propagating to children (like `setting :lm`)

## Key Decisions

1. **Context lives on Module, not Prompt** — Module-level `context` setting that propagates to inner Predict calls, similar to how `lm` propagates today.

2. **Context modules are named markdown strings** — No special typing. Each module is a `{ name: String, content: String }` pair. The content is freeform markdown. Structure comes from composition, not from typing individual pieces.

3. **Start with composition only** — No optimization support initially. MIPROv2 integration (rewriting, reordering, pruning context modules) is future work.

4. **Rendering position** — Context modules render in the system prompt before the schema/format sections, acting as a preamble that sets the stage before the structured I/O instructions.

## Design Sketch

### Declaration

```ruby
class MedicalAgent < DSPy::Module
  setting :context, default: []

  def initialize
    configure do |c|
      c.context = [
        { name: "persona", content: "You are a medical coding assistant..." },
        { name: "rules", content: File.read("guardrails.md") }
      ]
    end
    @predict = DSPy::Predict.new(DiagnosisSignature)
  end
end
```

### Propagation Path

```
Module.context
  -> LM#build_messages reads inference_module's context
  -> Prompt#render_system_prompt receives context sections
  -> Rendered as markdown sections before schema in system prompt
```

### Rendered System Prompt (conceptual)

```
## Persona
You are a medical coding assistant...

## Rules
[contents of guardrails.md]

Your input schema fields are:
...

In adhering to this structure, your objective is: ...
```

## Open Questions

1. **Propagation mechanics** — How exactly does Module context reach `Prompt#render_system_prompt`? Options:
   - LM reads context from the inference_module and prepends it to the rendered system prompt
   - Prompt gains an optional `context_sections` parameter
   - A new `ContextualPrompt` wrapper that decorates any Prompt with context

2. **Scoping** — Should some context modules apply only to specific inner Predict calls? (e.g., "tool usage rules" only for thought_generator, not observation_processor). Defer for now?

3. **Ordering** — Does the order of context modules matter? Should users control it explicitly?

4. **Deduplication** — If a nested Module also declares context, do they merge? Override? Append?

5. **Optimization surface** — When we add MIPROv2 support later, should context modules be optimizable independently (like instructions and examples are today)?

## Future Possibilities

- **Optimizable context**: MIPROv2 rewrites context modules based on evaluation metrics
- **Context scoping**: Attach specific context modules to specific inner predictions
- **Context from files**: DSL for loading context from markdown files with auto-reload
- **Context registry**: Share context modules across agents (like a skill library)
